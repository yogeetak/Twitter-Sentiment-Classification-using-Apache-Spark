{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                  CS491:Intro to Data Science Homework4\n",
    "                            Twitter Sentiment Classification Using Apache Spark\n",
    "                                  Group : Janani Neelakantan 670805407\n",
    "                                          Yogeeta Monica Kuttabadkar 661868770"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation instructions: \n",
    "1) Requires nltk package. Install using !pip install nltk if installing directly in the Jupyter notebook\n",
    "2) Requires complete nltk download for all other dependencies required in this program such as stopword list, tokenize method, stemmer etc.\n",
    "    - Do nltk.download()\n",
    "    - When prompted give option d) and then enter\n",
    "    - Again type 'all' and enter\n",
    "3) Create a Spark Context. Ensure train.csv and test.csv are in the /home/jovyan/work folder. In addition, train.csv and test.csv should first be saved with UTF encoding format. The program does not handle conversion to UTF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pyspark\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from pyspark.mllib.feature import HashingTF, IDF\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel \n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel, LogisticRegressionWithSGD\n",
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext(\"local[*]\")\n",
    "trainFileName = \"train.csv\"\n",
    "testFileName = \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TWEET PROCESSING\n",
    "The tweet processing for entire training and test data is performed using pyspark map. The following are the steps for cleaning:\n",
    "- Each entry/row in the csv file is split by ','. This is done to separate out each column.\n",
    "- One problem with the above is that since tweet text could also contain the character ',' the entire tweet text gets split into parts. The complete tweet text is then reframed using all the split parts.\n",
    "- All characters are converted to lower case\n",
    "- All digits are removed.\n",
    "- @username is replaced with AT_USER\n",
    "- URLs starting with www, http or https are replaced with URL\n",
    "- Replace 'm with am, 'd with would, 're with are, 'll with will and more\n",
    "- Replace 's with ' '. This will take care of words such as women's, bag's etc\n",
    "- Replace more than 2 occurrences of a character in a word with two occurrences. For instance exxxcitteddd will become exxcittedd\n",
    "- All special characters removed\n",
    "- All stopwords mentioned in nltk are removed\n",
    "- Snowball Stemmer used to reduce word to root form. We preferred Snowball over Porter because it is more accurate\n",
    "\n",
    "For better cleaning, implement SpellChecker using enchant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseTweet(line):\n",
    "    words=[]\n",
    "    parts=line.split(',')\n",
    "    label=parts[0]\n",
    "    tweetText=parts[5]\n",
    "    if len(parts)>5:                                         #Handling commas between the tweets\n",
    "        for i in range(6,len(parts)):\n",
    "            tweetText=tweetText+\" \"+parts[i]\n",
    "    tweetText=tweetText.strip().lower()                      #remove trailing spaces\n",
    "    tweetText = re.sub(\"\\d\", '', tweetText)                  #remove digits\n",
    "    tweetText = re.sub(r'\\-', ' ', tweetText)                #replace - with white space\n",
    "    tweetText = re.sub(r'\\@[\\w]*','AT_USER', tweetText)      #replace @username with AT_USER\n",
    "    tweetText = re.sub('(www\\.[^\\s]+)', ' URL ', tweetText)  #replace www. urls with URL\n",
    "    tweetText = re.sub('(http://[^\\s]+)',' URL ',tweetText)  #replace http: urls  with URL\n",
    "    tweetText = re.sub('(https://[^\\s]+)',' URL ',tweetText) #replace https: urls with URL\n",
    "    tweetText = re.sub(r'\\'m', ' am', tweetText)             #replace apostrophe m ('m) with am\n",
    "    tweetText = re.sub(r'\\'d', ' would', tweetText)          #replace apostrophe d ('d) with would\n",
    "    tweetText = re.sub(r'\\'re', ' are', tweetText)           #replace apostrophe re ('re) with are\n",
    "    tweetText = re.sub(r'n\\'t', ' not', tweetText)           #replace apostrophe t ('nt) with not\n",
    "    tweetText = re.sub(r'\\'ll', ' will', tweetText)          #replace apostrophe ll ('ll) with will\n",
    "    tweetText = re.sub(r'\\&', 'and', tweetText)              #replace & with and\n",
    "    tweetText = re.sub(r'didnt ', 'did not', tweetText)      #replace didnt  with did not\n",
    "    tweetText = re.sub(r'dont', 'do not', tweetText)         #replace dont with do not\n",
    "    tweetText = re.sub(r'wont', 'will not', tweetText)       #replace wont with will not\n",
    "    tweetText = re.sub(r'cant', 'can not', tweetText)        #replace cant with can not \n",
    "    tweetText = re.sub(r'wouldnt', 'would not', tweetText)   #replace wouldnt with would not\n",
    "    tweetText = re.sub(r'couldnt', 'could not', tweetText)   #replace couldnt with could not\n",
    "    tweetText = re.sub(r'isnt', 'is not', tweetText)         #replace isnt with is not\n",
    "    tweetText = re.sub(r'wasnt', 'was not', tweetText)       #replace wasnt with was not\n",
    "    tweetText = re.sub(r'\\'s', ' ', tweetText)               #replacing any apostrphe ('s) with empty space\n",
    "    tweetText = re.sub(r'([a-z])\\1+',r'\\1\\1', tweetText)     #replacing more than 2 occurences of a charater\n",
    "    #tweetText = re.sub('\\W', ' ', tweetText)                 #replacing any alphanumeric characters\n",
    "   \n",
    "    ##Stop Words,Punctuation and Stemming\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    PUNCTUATION = set(string.punctuation)\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    token_words=word_tokenize(tweetText)\n",
    "    filtered_tweet=[w for w in token_words if not w in stop_words]\n",
    "    for word in filtered_tweet:\n",
    "        if(word == \"AT_USER\" or word == \"URL\"):\n",
    "            words.append(word)\n",
    "            continue\n",
    "        punct_removed = ''.join([letter for letter in word if not letter in PUNCTUATION])  \n",
    "        stemmedWord = stemmer.stem(punct_removed)\n",
    "        words.append(str(stemmedWord))\n",
    "    tweetText = ' '.join(words)\n",
    "    return(label,tweetText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAIVE BAYES MODEL AND PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train a Naive Bayes model on the training data\n",
    "def NaiveBayesClassifier(trainRDD):\n",
    "    NV_model = NaiveBayes.train(trainRDD)\n",
    "    return NV_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Testing the model on the test data\n",
    "def NaiveBayesPrediction(NV_model, testRDD):     \n",
    "    FPR = []\n",
    "    TPR = []\n",
    "    \n",
    "    # Compare predicted labels to actual labels\n",
    "    prediction_and_labels = testRDD.map(lambda point: (float(NV_model.predict(point.features)), point.label))    \n",
    "    # Filter to only correct predictions\n",
    "    correct = prediction_and_labels.filter(lambda predicted: predicted[0] == predicted[1])    \n",
    "    # Calculate and print accuracy rate\n",
    "    accuracy =  correct.count() / float(testRDD.count())    \n",
    "    print(\"NB_accuracy = \" + str(accuracy))   \n",
    "    \n",
    "    labels = testRDD.map(lambda lp: lp.label).distinct().collect()\n",
    "    calculateMetrics(prediction_and_labels, labels) \n",
    "    calculateBinaryMetrics(prediction_and_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION MODEL - LBFGS ; SGD ; PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic Regression with LBFGS\n",
    "def LogisticRegressionClassifierWithL2(trainRDD):\n",
    "    # Build the model\n",
    "    LR_model = LogisticRegressionWithLBFGS.train(trainRDD, regType=\"l2\")\n",
    "    return LR_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic Regression with SGD\n",
    "def LogisticRegressionClassifierSGD(trainRDD):\n",
    "    # Build the model\n",
    "    LR_model = LogisticRegressionWithSGD.train(trainRDD)\n",
    "    return LR_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluating the model on testing data\n",
    "def LogisticRegressionPrediction(LR_model, testRDD):\n",
    "    #labelsAndPreds = testRDD.map(lambda p: (p.label, float(LR_model.predict(p.features))))\n",
    "    labelsAndPreds = testRDD.map(lambda lp: (float(LR_model.predict(lp.features)), lp.label))\n",
    "    correct = labelsAndPreds.filter(lambda v: v[0] == v[1])\n",
    "    accuracy = correct.count() / float(testRDD.count())\n",
    "    print(\"LR_accuracy = \" + str(accuracy))\n",
    "    \n",
    "    labels = testRDD.map(lambda lp: lp.label).distinct().collect()    \n",
    "    calculateMetrics(labelsAndPreds, labels)\n",
    "    calculateBinaryMetrics(labelsAndPreds)\n",
    "    return accuracy  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREE MODEL AND PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Decision Tree classifier \n",
    "def DecisionTreeClassifier(trainRDD):\n",
    "    # Build the model\n",
    "    DT_model = DecisionTree.trainClassifier(trainRDD, numClasses=2, categoricalFeaturesInfo={}, impurity='gini', maxDepth=5, maxBins=32)\n",
    "    return DT_model    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Decision Tree classifier \n",
    "def DecisionTreeRegressor(trainRDD):\n",
    "    # Build the model\n",
    "    DT_model = DecisionTree.trainRegressor(trainRDD, categoricalFeaturesInfo={}, impurity='variance', maxDepth=5, maxBins=32)\n",
    "    return DT_model    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating the model on test data\n",
    "def DecisionTreePrediction(DT_model, testRDD):\n",
    "    predictions = DT_model.predict(testRDD.map(lambda x: x.features))\n",
    "    labelsAndPredictions = testRDD.map(lambda lp: lp.label).zip(predictions)\n",
    "    DT_accuracy = labelsAndPredictions.filter(lambda t:t[0] == t[1]).count() / float(testRDD.count())\n",
    "    print(\"DT_accuracy = \" + str(DT_accuracy))\n",
    "    \n",
    "    labels = testRDD.map(lambda lp: lp.label).distinct().collect()    \n",
    "    calculateMetrics(labelsAndPredictions, labels)\n",
    "    calculateBinaryMetrics(labelsAndPredictions)\n",
    "    return DT_accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPUTING HASHING TF WITH 'N' NUMBER OF FEATURES\n",
    "Create Labeled Point with label and TF feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Only HashingTF as the feature with n feature values\n",
    "def computeTF(featureVal, data_cleaned):\n",
    "    # Hashing term frequency vectorizer with 'x' features\n",
    "    htf=HashingTF(featureVal)\n",
    "    \n",
    "    # Create an RDD of LabeledPoints using category labels as labels and tokenized, hashed text as feature vectors\n",
    "    labeled_training_data = data_cleaned.map(lambda label: LabeledPoint(label[0], htf.transform(label[1])))\n",
    "    \n",
    "    return labeled_training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute hashing TF with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Only HashingTF as the feature with all feature values\n",
    "def computeTFAll(data_cleaned):\n",
    "    # Hashing term frequency vectorizer with all features\n",
    "    htf=HashingTF()\n",
    "    \n",
    "    # Create an RDD of LabeledPoints using category labels as labels and tokenized, hashed text as feature vectors\n",
    "    labeled_training_data = data_cleaned.map(lambda label: LabeledPoint(label[0], htf.transform(label[1])))\n",
    "    \n",
    "    return labeled_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Computing TF-IDF Type 2\n",
    "def computeTFIDF(data_cleaned):\n",
    "    # Split data into labels and features, transform\n",
    "    labels = data_cleaned.map(lambda doc: doc[0])\n",
    "    \n",
    "    tf = HashingTF(100).transform(data_cleaned.map(lambda doc:doc[1]))\n",
    "    idf = IDF().fit(tf)\n",
    "    tfidf = idf.transform(tf)\n",
    "    \n",
    "    # Combine using zip\n",
    "    labeled_training_data = labels.zip(tfidf).map(lambda x: LabeledPoint(x[0], x[1]))\n",
    "    \n",
    "    return labeled_training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Method to calculate metrics of predictions from trained model\n",
    "def calculateMetrics(labels_and_predictions, labels):\n",
    "    TPR = []\n",
    "    FPR = []\n",
    "    metrics = MulticlassMetrics(labels_and_predictions)    \n",
    "    \n",
    "    # Overall statistics\n",
    "    precision = metrics.weightedPrecision\n",
    "    recall = metrics.weightedRecall\n",
    "    f1Score = metrics.weightedFMeasure()\n",
    "    confusionMatrix = metrics.confusionMatrix().toArray()\n",
    "    print(\"Summary Stats\")\n",
    "    print(\"Average Precision = %s\" % precision)\n",
    "    print(\"Average Recall = %s\" % recall)\n",
    "    print(\"Average F1 Score = %s\" % f1Score)\n",
    "    print(\"Confusion Matrix = %s\" % confusionMatrix)\n",
    "    \n",
    "    '''\n",
    "    # Weighted statistics\n",
    "    print(\"Weighted recall = %s\" % metrics.weightedRecall())\n",
    "    print(\"Weighted precision = %s\" % metrics.weightedPrecision())\n",
    "    print(\"Weighted F(1) Score = %s\" % metrics.weightedFMeasure())\n",
    "    print(\"Weighted F(0.5) Score = %s\" % metrics.weightedFMeasure(beta=0.5))\n",
    "    '''\n",
    "    FPRW = metrics.weightedFalsePositiveRate\n",
    "    TPRW = metrics.weightedTruePositiveRate\n",
    "    print(\"Weighted false positive rate = %s\" % FPRW)\n",
    "    print(\"Weighted true positive rate = %s\" % TPRW)        \n",
    "    \n",
    "    for label in sorted(labels):\n",
    "        FPR.append(metrics.falsePositiveRate(label))\n",
    "        TPR.append(metrics.truePositiveRate(label))  \n",
    "        \n",
    "    plotROCcurve(FPR, TPR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateBinaryMetrics(labels_and_predictions):\n",
    "    metrics = BinaryClassificationMetrics(labels_and_predictions)\n",
    "    print(\"Area under PR = %s\" % metrics.areaUnderPR)\n",
    "    \n",
    "    # Area under ROC curve\n",
    "    print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotROCcurve(falsepositive, truepositive):\n",
    "    plt.figure(figsize=(4, 4), dpi=80)\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=14)\n",
    "    plt.ylabel(\"True Positive Rate\", fontsize=14)\n",
    "    plt.title(\"ROC Curve\", fontsize=14)\n",
    "    plt.plot(falsepositive, truepositive, color='red', linewidth=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotAccuracy(classifierName, trainingAccuracy, KFoldAccuracy, testAccuracy):\n",
    "    myfig = plt.figure()\n",
    "    myfig.suptitle(classifierName + ' - Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    myaxes = myfig.add_subplot(111)\n",
    "    myfig.subplots_adjust(top=0.85)\n",
    "    myaxes.set_title('Data')\n",
    "    myaxes.set_ylabel('Accuracy Percentage')\n",
    "    myaxes.xaxis.set_visible(False)\n",
    "    \n",
    "    N = 3\n",
    "    x = [1,2,3]\n",
    "    y = [trainingAccuracy, KFoldAccuracy, testAccuracy]\n",
    "    colors = ['red','green','blue']\n",
    "    area = 150\n",
    "    \n",
    "    myaxes.annotate('Training Accuracy', xy=(x[0],y[0]), xytext=(x[0], (y[0]-0.001)))   \n",
    "    myaxes.annotate('Avg K-Fold Accuracy', xy=(x[1],y[1]), xytext=(x[1], (y[1]-0.001)))\n",
    "    myaxes.annotate('Test Accuracy', xy=(x[2],y[2]), xytext=(x[2], (y[2]-0.001)))\n",
    "    \n",
    "    plt.scatter(x, y, s=area, c=colors, alpha=0.5)\n",
    "    \n",
    "    auc = np.trapz(y,x)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load train.csv as RDD and perform processing/cleaning\n",
    "alltrainData = sc.textFile(trainFileName)\n",
    "mapdata = alltrainData.map(parseTweet)\n",
    "\n",
    "#Split each tweet into words\n",
    "train_data_cleaned = mapdata.map(lambda label: (label[0],word_tokenize(label[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data 70/30 into training and test data sets\n",
    "train_random_set, test_random_set = trainedData1.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Computing feature vector TF for proceesed training data\n",
    "trainedData1 = computeTF(50000, train_data_cleaned)    #With number of features specified\n",
    "#trainedData1 = computeTFAll(train_data_cleaned)       #With all features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Naive Bayes training on all of the processed training data\n",
    "Naive_model = NaiveBayesClassifier(trainedData1)\n",
    "Naive_model.save(sc, \"/home/jovyan/work/myNaiveBayesModel10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing/prediction of Naives Bayes on training data\n",
    "Naive_model = NaiveBayesModel.load(sc, \"/home/jovyan/work/myNaiveBayesModel10\")\n",
    "Naive_accuracy = NaiveBayesPrediction(Naive_model, trainedData1)\n",
    "print(\"Naive Bayes accuracy = \" + str(Naive_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Computing feature vector TF for processed training data\n",
    "trainedData2 = computeTF(50000, train_data_cleaned)    #With number of features specified\n",
    "#trainedData = computeTFAll(train_data_cleaned)          #With all features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Logistic Regression training on all of the training data\n",
    "LR_model = LogisticRegressionClassifierWithL2(trainedData2)     \n",
    "#LR_model = LogisticRegressionClassifierSGD(trainedData)\n",
    "LR_model.save(sc, \"/home/jovyan/work/myLRModel5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing/prediction of Logistic Regression on training data\n",
    "LR_model = LogisticRegressionModel.load(sc, \"/home/jovyan/work/myLRModel5\")\n",
    "LR_accuracy = LogisticRegressionPrediction(LR_model, trainedData2)\n",
    "print(\"Logistic Regression accuracy = \" + str(LR_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Decision Tree training on all of the training data\n",
    "trainedData3 = computeTF(5000, train_data_cleaned)    #With number of features specified\n",
    "#trainedData = computeTFAll(data_cleaned)            #With all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DT_model = DecisionTreeClassifier(trainedData3)\n",
    "DT_model.save(sc, \"/home/jovyan/work/myDTModel4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#KFold method1\n",
    "RDDlist = []\n",
    "train1, test1 = labeled_training_data.randomSplit([0.9, 0.1])\n",
    "RDDlist.append(test1)\n",
    "train2, test2 = train1.randomSplit([0.9, 0.1])\n",
    "RDDlist.append(test2)\n",
    "train3, test3 = train2.randomSplit([0.9, 0.11])\n",
    "RDDlist.append(test3)\n",
    "train4, test4 = train3.randomSplit([0.9, 0.1])\n",
    "RDDlist.append(test4)\n",
    "train5, test5 = train4.randomSplit([0.9, 0.1])\n",
    "RDDlist.append(test5)\n",
    "train6, test6 = train5.randomSplit([0.9, 0.1])\n",
    "RDDlist.append(test6)\n",
    "train7, test7 = train6.randomSplit([0.9, 0.1])\n",
    "RDDlist.append(test7)\n",
    "train8, test8 = train7.randomSplit([0.9, 0.1])\n",
    "RDDlist.append(test8)\n",
    "train9, test9 = train8.randomSplit([0.9, 0.1])\n",
    "RDDlist.append(test9)\n",
    "train10, test10 = train9.randomSplit([0.9, 0.1])\n",
    "RDDlist.append(test10)\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(RDDlist[i].count())\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#10-Fold validation method \n",
    "def KFoldValidation(modelName, labeled_training_data):\n",
    "    print(modelName)\n",
    "    RDDlist = []\n",
    "    RDDlist = labeled_training_data.randomSplit([0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1])\n",
    "    accuracy_list = []\n",
    "    \n",
    "    for i in range(0,10):\n",
    "        k=1\n",
    "        training_KF_data = sc.emptyRDD()        \n",
    "        for j in range(0,10):\n",
    "            if(i == j):\n",
    "                test_KF_data = RDDlist[j]\n",
    "            else:\n",
    "                if(k == 1):\n",
    "                    training_KF_data = RDDlist[j]\n",
    "                else:\n",
    "                    training_KF_data = training_KF_data.union(RDDlist[j])   \n",
    "                k = k + 1\n",
    "            \n",
    "            \n",
    "        if(modelName is 'NaiveBayes'):\n",
    "            NV_model = NaiveBayesClassifier(training_KF_data)\n",
    "            NV_accuracy = NaiveBayesPrediction(NV_model, test_KF_data)\n",
    "            print(NV_accuracy)\n",
    "            accuracy_list.append(NV_accuracy)\n",
    "                \n",
    "        elif(modelName is 'LogisticRegression'):\n",
    "            LR_model = LogisticRegressionClassifierWithL2(training_KF_data)\n",
    "            LR_accuracy = LogisticRegressionPrediction(LR_model, test_KF_data)\n",
    "            print(LR_accuracy)\n",
    "            accuracy_list.append(LR_accuracy)\n",
    "        \n",
    "        else:\n",
    "            DT_model = DecisionTreeClassifier(training_KF_data)\n",
    "            DT_accuracy = DecisionTreePrediction(DT_model, test_KF_data)\n",
    "            print(DT_accuracy)\n",
    "            accuracy_list.append(DT_accuracy)\n",
    "                \n",
    "    avg_accuracy = sum(accuracy_list)/10.0\n",
    "    print(\"10 fold validation accuracy for \" + modelName + \" = \" + str(avg_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainedDataNew = computeTFAll(train_data_cleaned) \n",
    "KFoldValidation('NaiveBayes', trainedDataNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainedDataNew = computeTFAll(train_data_cleaned) \n",
    "KFoldValidation('LogisticRegression', trainedDataNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainedDataNew = computeTF(5000,train_data_cleaned) \n",
    "KFoldValidation('DecisionTree', trainedDataNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load test.csv as RDD and perform processing/cleaning\n",
    "alltestData = sc.textFile(testFileName)\n",
    "mapdata = alltestData.map(parseTweet)\n",
    "\n",
    "#Split each tweet into words\n",
    "test_data_cleaned = mapdata.map(lambda label: (label[0],word_tokenize(label[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testData1 = computeTF(50000, test_data_cleaned)\n",
    "#testData1 = computeTFAll(test_data_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing/prediction of Naives Bayes on test data\n",
    "Naive_model = NaiveBayesModel.load(sc, \"/home/jovyan/work/myNaiveBayesModel2\")\n",
    "Naive_accuracy = NaiveBayesPrediction(Naive_model, testData1)\n",
    "print(\"Naive Bayes accuracy = \" + str(Naive_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testData3 = computeTF(50000, test_data_cleaned)\n",
    "#testData2 = computeTFAll(test_data_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing/prediction of Logistic Regression on test data\n",
    "LR_model = LogisticRegressionModel.load(sc, \"/home/jovyan/work/myLRModel5\")\n",
    "LR_accuracy = LogisticRegressionPrediction(LR_model, testData3)\n",
    "print(\"Logistic Regression accuracy = \" + str(LR_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testData3 = computeTF(1000, test_data_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing/prediction of Decision Tree on test data\n",
    "DT_model = DecisionTreeModel.load(sc, \"/home/jovyan/work/myDTModel3\")\n",
    "DT_accuracy = DecisionTreePrediction(DT_model, testData3)\n",
    "print(\"Decision Tree accuracy = \" + str(DT_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotAccuracy('Naive Bayes',81.81, 71.79, 78.27)\n",
    "plotAccuracy('Logistic Regression', 74.56, 73.89, 74.09)\n",
    "plotAccuracy('Decision Tree', 61.55, 0 , 59.61)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
